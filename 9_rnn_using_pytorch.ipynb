{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recurrent Neural Networks  \n",
    "RNNs are a type of neural networks designed for processing sequential data.  \n",
    "They maintain a memory of previous inputs.  \n",
    "It excels in usecases where context and order matter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flow: \n",
    "- Read textual data  \n",
    "- Convert text data into embeddings(words into numbers)  \n",
    "- create a model  \n",
    "- train the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/100_Unique_QA_Dataset (1).csv\")\n",
    "df.head()\n",
    "new_data = {\n",
    "    \"Who is the most beautiful woman in the world?\": \"Aayushi\",\n",
    "    \"Whom does Geet love the most?\": \"Aayushi\",\n",
    "    \"Who makes Geet's heart skip a beat?\": \"Aayushi\",\n",
    "    \"Who is the queen of Geet's world?\": \"Aayushi\",\n",
    "    \"Who has the most gorgeous smile ever?\": \"Aayushi\",\n",
    "    \"Who lights up Geet's life like a thousand suns?\": \"Aayushi\",\n",
    "    \"Who is the one Geet can't live without?\": \"Aayushi\",\n",
    "    \"Who is Geet's forever crush?\": \"Aayushi\",\n",
    "    \"Who rules Geet's heart?\": \"Aayushi\",\n",
    "    \"Who is Geet's definition of perfection?\": \"Aayushi\",\n",
    "    \"Who deserves all the love poems in the world?\": \"Aayushi\",\n",
    "    \"Who is the sunshine on a rainy day for Geet?\": \"Aayushi\",\n",
    "    \"Who is the love of Geet’s life?\": \"Aayushi\",\n",
    "    \"Who is the most special person to Geet?\": \"Aayushi\",\n",
    "    \"Who does Geet adore the most?\": \"Aayushi\",\n",
    "    \"Who is the only name in Geet’s playlist of love?\": \"Aayushi\",\n",
    "    \"If Geet had one wish, who would he wish for?\": \"Aayushi\",\n",
    "    \"Who is the most magical woman ever?\": \"Aayushi\",\n",
    "    \"Who makes Geet smile just by existing?\": \"Aayushi\",\n",
    "    \"Who is the star of every dream Geet has?\": \"Aayushi\",\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(list(new_data.items()), columns=[\"question\", \"answer\"])\n",
    "\n",
    "df = pd.concat([df, new_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text= text.lower()\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    text = text.replace('\"', '')\n",
    "    text = text.replace(\"?\", \"\")\n",
    "    text = text.split(\" \")\n",
    "    return text\n",
    "\n",
    "def create_vocab(df):\n",
    "    create_vocab = set()\n",
    "    for i in range(len(df)):\n",
    "        question = tokenize(df['question'][i])\n",
    "        answer = tokenize(df['answer'][i])\n",
    "        create_vocab.update(question)\n",
    "        create_vocab.update(answer)\n",
    "    return list(create_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " 'from': 1,\n",
       " 'albert-einstein': 2,\n",
       " 'whale': 3,\n",
       " 'main': 4,\n",
       " 'discovered': 5,\n",
       " 'breathe': 6,\n",
       " 'color': 7,\n",
       " 'net,': 8,\n",
       " 'kill': 9,\n",
       " 'tower': 10,\n",
       " 'author': 11,\n",
       " 'romeo': 12,\n",
       " 'did': 13,\n",
       " 'directed': 14,\n",
       " '64': 15,\n",
       " 'room': 16,\n",
       " 'tokyo': 17,\n",
       " 'united': 18,\n",
       " '28': 19,\n",
       " 'humans': 20,\n",
       " 'pinocchio': 21,\n",
       " 'body': 22,\n",
       " 'in': 23,\n",
       " 'lying': 24,\n",
       " 'spain': 25,\n",
       " 'germany': 26,\n",
       " 'cant': 27,\n",
       " 'electricity': 28,\n",
       " 'common': 29,\n",
       " 'step': 30,\n",
       " 'rainy': 31,\n",
       " 'pound': 32,\n",
       " 'how': 33,\n",
       " 'geet’s': 34,\n",
       " 'would': 35,\n",
       " 'great': 36,\n",
       " 'margaretthatcher': 37,\n",
       " 'brasilia': 38,\n",
       " 'gas': 39,\n",
       " '1': 40,\n",
       " 'disney': 41,\n",
       " 'mango': 42,\n",
       " 'end': 43,\n",
       " 'developed': 44,\n",
       " 'gold': 45,\n",
       " 'most': 46,\n",
       " 'iron': 47,\n",
       " 'freezing': 48,\n",
       " 'adult': 49,\n",
       " 'gorgeous': 50,\n",
       " 'year': 51,\n",
       " 'forever': 52,\n",
       " 'every': 53,\n",
       " 'substance': 54,\n",
       " 'root': 55,\n",
       " 'arms': 56,\n",
       " 'long': 57,\n",
       " 'show': 58,\n",
       " 'sunshine': 59,\n",
       " 'india': 60,\n",
       " 'collect': 61,\n",
       " 'formula': 62,\n",
       " 'many': 63,\n",
       " 'first': 64,\n",
       " 'study': 65,\n",
       " 'to': 66,\n",
       " '1945': 67,\n",
       " 'bees': 68,\n",
       " 'creature': 69,\n",
       " 'batman': 70,\n",
       " 'thousand': 71,\n",
       " '1492': 72,\n",
       " 'had': 73,\n",
       " 'fe': 74,\n",
       " 'a': 75,\n",
       " 'vacuum': 76,\n",
       " '6': 77,\n",
       " 'rome': 78,\n",
       " 'name': 79,\n",
       " 'on': 80,\n",
       " 'pyramids': 81,\n",
       " 'giza': 82,\n",
       " 'element': 83,\n",
       " 'continent': 84,\n",
       " 'continents': 85,\n",
       " 'italy': 86,\n",
       " 'lights': 87,\n",
       " 'paris': 88,\n",
       " 'jupiter': 89,\n",
       " 'aayushi': 90,\n",
       " 'rules': 91,\n",
       " 'colors': 92,\n",
       " 'computers': 93,\n",
       " 'natural': 94,\n",
       " 'without': 95,\n",
       " 'basketball': 96,\n",
       " 'language': 97,\n",
       " 'minister': 98,\n",
       " 'point': 99,\n",
       " 'all': 100,\n",
       " 'celsius': 101,\n",
       " 'up': 102,\n",
       " 'tv': 103,\n",
       " 'survival': 104,\n",
       " 'south': 105,\n",
       " 'plants': 106,\n",
       " 'spoken': 107,\n",
       " 'nectar': 108,\n",
       " 'land': 109,\n",
       " 'also': 110,\n",
       " 'ingredient': 111,\n",
       " 'bulb': 112,\n",
       " 'superhero': 113,\n",
       " 'ever': 114,\n",
       " 'hexagon': 115,\n",
       " 'simpsons': 116,\n",
       " '1984': 117,\n",
       " 'uk': 118,\n",
       " 'chemical': 119,\n",
       " 'nose': 120,\n",
       " 'love': 121,\n",
       " 'knight': 122,\n",
       " '7': 123,\n",
       " 'which': 124,\n",
       " 'h2o': 125,\n",
       " 'apple': 126,\n",
       " 'banana': 127,\n",
       " 'is': 128,\n",
       " 'ii': 129,\n",
       " 'ripe': 130,\n",
       " 'second-largest': 131,\n",
       " 'madrid': 132,\n",
       " 'number': 133,\n",
       " 'asia': 134,\n",
       " 'of': 135,\n",
       " '8': 136,\n",
       " 'wish': 137,\n",
       " 'whom': 138,\n",
       " 'day': 139,\n",
       " 'saturn': 140,\n",
       " '100': 141,\n",
       " 'who': 142,\n",
       " 'newton': 143,\n",
       " 'bird': 144,\n",
       " 'berlin': 145,\n",
       " 'dream': 146,\n",
       " 'february': 147,\n",
       " 'spider': 148,\n",
       " 'war': 149,\n",
       " 'lisa': 150,\n",
       " 'earths': 151,\n",
       " 'king': 152,\n",
       " 'queen': 153,\n",
       " 'relativity': 154,\n",
       " 'smallest': 155,\n",
       " 'solar': 156,\n",
       " 'night': 157,\n",
       " 'grows': 158,\n",
       " 'sun': 159,\n",
       " 'beat': 160,\n",
       " 'wrote': 161,\n",
       " 'kingdom': 162,\n",
       " 'penicillin': 163,\n",
       " 'sea': 164,\n",
       " 'geets': 165,\n",
       " 'animal': 166,\n",
       " 'just': 167,\n",
       " 'sport': 168,\n",
       " 'harper-lee': 169,\n",
       " 'mammal': 170,\n",
       " 'has': 171,\n",
       " 'definition': 172,\n",
       " 'star': 173,\n",
       " 'sides': 174,\n",
       " 'oxygen': 175,\n",
       " 'one': 176,\n",
       " '299,792,458m/s': 177,\n",
       " 'river': 178,\n",
       " 'france': 179,\n",
       " 'earth': 180,\n",
       " 'when': 181,\n",
       " 'states': 182,\n",
       " 'christophercolumbus': 183,\n",
       " 'do': 184,\n",
       " 'canada': 185,\n",
       " 'the': 186,\n",
       " 'metal': 187,\n",
       " 'fahrenheit': 188,\n",
       " 'hoop': 189,\n",
       " 'character': 190,\n",
       " 'temperature': 191,\n",
       " 'deserves': 192,\n",
       " 'only': 193,\n",
       " 'gravity': 194,\n",
       " 'area': 195,\n",
       " 'crush': 196,\n",
       " 'moon': 197,\n",
       " 'benjamin-franklin': 198,\n",
       " 'light': 199,\n",
       " 'month': 200,\n",
       " 'george-orwell': 201,\n",
       " 'boiling': 202,\n",
       " 'are': 203,\n",
       " 'symbol': 204,\n",
       " 'existing': 205,\n",
       " 'americas': 206,\n",
       " 'famous': 207,\n",
       " 'person': 208,\n",
       " 'red': 209,\n",
       " 'system': 210,\n",
       " 'ability': 211,\n",
       " 'wall': 212,\n",
       " 'days': 213,\n",
       " 'was': 214,\n",
       " 'mockingbird': 215,\n",
       " 'mexicocity': 216,\n",
       " 'poems': 217,\n",
       " 'hydrogen': 218,\n",
       " 'it': 219,\n",
       " 'world': 220,\n",
       " 'speed': 221,\n",
       " 'fruits': 222,\n",
       " 'president': 223,\n",
       " 'keys': 224,\n",
       " 'our': 225,\n",
       " 'and': 226,\n",
       " 'prime': 227,\n",
       " 'mona': 228,\n",
       " 'city': 229,\n",
       " 'armstrong': 230,\n",
       " 'holiday': 231,\n",
       " 'what': 232,\n",
       " 'white': 233,\n",
       " '12': 234,\n",
       " 'living': 235,\n",
       " 'nile': 236,\n",
       " 'sushi': 237,\n",
       " 'celebrated': 238,\n",
       " 'delhi': 239,\n",
       " 'closest': 240,\n",
       " 'newyork': 241,\n",
       " 'ball,': 242,\n",
       " 'photosynthesis': 243,\n",
       " 'movie': 244,\n",
       " 'atmosphere': 245,\n",
       " 'legs': 246,\n",
       " 'liquid': 247,\n",
       " 'canberra': 248,\n",
       " 'as': 249,\n",
       " 'korea': 250,\n",
       " 'have': 251,\n",
       " 'beautiful': 252,\n",
       " 'flowers': 253,\n",
       " 'woman': 254,\n",
       " 'rainbow': 255,\n",
       " 'skip': 256,\n",
       " 'diamond': 257,\n",
       " 'jane-austen': 258,\n",
       " 'tallest': 259,\n",
       " 'live': 260,\n",
       " '32': 261,\n",
       " 'if': 262,\n",
       " 'geet': 263,\n",
       " 'fruit': 264,\n",
       " 'called': 265,\n",
       " 'alexander-fleming': 266,\n",
       " 'there': 267,\n",
       " 'adore': 268,\n",
       " 'nitrogen': 269,\n",
       " 'prejudice': 270,\n",
       " 'eight': 271,\n",
       " 'portuguese': 272,\n",
       " 'seoul': 273,\n",
       " 'periodic': 274,\n",
       " 'guacamole': 275,\n",
       " 'currency': 276,\n",
       " 'black': 277,\n",
       " 'use': 278,\n",
       " 'vangogh': 279,\n",
       " 'yuan': 280,\n",
       " 'water': 281,\n",
       " '206': 282,\n",
       " 'capital': 283,\n",
       " 'egypt': 284,\n",
       " 'pacific-ocean': 285,\n",
       " 'makes': 286,\n",
       " 'instrument': 287,\n",
       " 'brazil': 288,\n",
       " 'largest': 289,\n",
       " 'suns': 290,\n",
       " 'alexander-graham-bell': 291,\n",
       " 'ocean': 292,\n",
       " 'mercury': 293,\n",
       " 'dark': 294,\n",
       " 'magical': 295,\n",
       " 'ottawa': 296,\n",
       " 'opposite': 297,\n",
       " 'special': 298,\n",
       " 'its': 299,\n",
       " 'mars': 300,\n",
       " 'square': 301,\n",
       " '2': 302,\n",
       " 'vaticancity': 303,\n",
       " '144': 304,\n",
       " 'mimic': 305,\n",
       " 'hardest': 306,\n",
       " 'eiffel': 307,\n",
       " 'moons': 308,\n",
       " 'animated': 309,\n",
       " 'december': 310,\n",
       " 'pride': 311,\n",
       " 'starry': 312,\n",
       " 'planets': 313,\n",
       " 'telephone': 314,\n",
       " 'avocado': 315,\n",
       " 'does': 316,\n",
       " 'planet': 317,\n",
       " 'charlesbabbage': 318,\n",
       " 'china': 319,\n",
       " 'biology': 320,\n",
       " 'smile': 321,\n",
       " 'father': 322,\n",
       " 'mountain': 323,\n",
       " 'life': 324,\n",
       " 'like': 325,\n",
       " 'country': 326,\n",
       " 'sounds': 327,\n",
       " 'yellow': 328,\n",
       " 'for': 329,\n",
       " 'known': 330,\n",
       " 'japan': 331,\n",
       " 'female': 332,\n",
       " 'shakespeare': 333,\n",
       " 'mexico': 334,\n",
       " 'musical': 335,\n",
       " 'leonardo-da-vinci': 336,\n",
       " 'uses': 337,\n",
       " '25': 338,\n",
       " 'human': 339,\n",
       " 'juliet': 340,\n",
       " 'george-washington': 341,\n",
       " 'big': 342,\n",
       " 'parrot': 343,\n",
       " 'everest': 344,\n",
       " 'fastest': 345,\n",
       " 'heart': 346,\n",
       " 'organisms': 347,\n",
       " 'table': 348,\n",
       " 'bones': 349,\n",
       " 'octopus': 350,\n",
       " 'playlist': 351,\n",
       " 'home': 352,\n",
       " 'kangaroos': 353,\n",
       " 'longest': 354,\n",
       " 'co2': 355,\n",
       " 'invented': 356,\n",
       " 'cheetah': 357,\n",
       " 'jamescameron': 358,\n",
       " 'christmas': 359,\n",
       " 'piano': 360,\n",
       " 'russia': 361,\n",
       " 'moscow': 362,\n",
       " 'atomic': 363,\n",
       " 'au': 364,\n",
       " 'wish,': 365,\n",
       " 'by': 366,\n",
       " 'longest-running': 367,\n",
       " 'at': 368,\n",
       " 'yen': 369,\n",
       " 'painted': 370,\n",
       " 'perfection': 371,\n",
       " 'edison': 372,\n",
       " 'titanic': 373,\n",
       " 'he': 374,\n",
       " 'theory': 375,\n",
       " 'australia': 376}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = create_vocab(df)\n",
    "def vocab_to_dict(vocab):\n",
    "    vocab_dict = {'<unk>': 0}\n",
    "    for idx, word in enumerate(vocab):\n",
    "        vocab_dict[word] = idx + 1\n",
    "    \n",
    "    return vocab_dict\n",
    "\n",
    "vocab_dict = vocab_to_dict(vocab)\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124, 128, 186, 0, 317]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_index(text, vocab_dict):\n",
    "    text = tokenize(text)\n",
    "    text_index = []\n",
    "    for word in text:\n",
    "        if word in vocab_dict.keys():\n",
    "            text_index.append(vocab_dict[word])\n",
    "        else:\n",
    "            text_index.append(vocab_dict['<unk>'])\n",
    "    if len(text_index) == 1:\n",
    "        return text_index[0]\n",
    "    else:\n",
    "        return text_index\n",
    "\n",
    "text_to_index(\"WHICH is the third Planet\", vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[232, 128, 186, 283, 135, 179]</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[232, 128, 186, 283, 135, 26]</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[142, 161, 66, 9, 75, 215]</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[232, 128, 186, 289, 317, 23, 225, 156, 210]</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[232, 128, 186, 202, 99, 135, 281, 23, 101]</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question  answer\n",
       "0                [232, 128, 186, 283, 135, 179]      88\n",
       "1                 [232, 128, 186, 283, 135, 26]     145\n",
       "2                    [142, 161, 66, 9, 75, 215]     169\n",
       "3  [232, 128, 186, 289, 317, 23, 225, 156, 210]      89\n",
       "4   [232, 128, 186, 202, 99, 135, 281, 23, 101]     141"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question'] = df['question'].apply(lambda x: text_to_index(x, vocab_dict))\n",
    "df['answer'] = df['answer'].apply( lambda x: text_to_index(x, vocab_dict))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qadatset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.features = df.question\n",
    "        self.labels = df.answer\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx]), torch.tensor(self.labels[idx])\n",
    "\n",
    "train_dataset = qadatset(df)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Data: tensor([[124, 326, 128, 352,  66, 186,  36, 212]])\n",
      "Label: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (data, label) in enumerate(train_dataloader):\n",
    "    print(f\"Batch {idx+1}\")\n",
    "    print(\"Data:\", data)\n",
    "    print(\"Label:\", label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myrnnmodel(\n",
       "  (embedding): Embedding(377, 64)\n",
       "  (rnn): RNN(64, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=377, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myrnnmodel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding =   nn.Embedding(\n",
    "                num_embeddings=vocab_size, \n",
    "                embedding_dim=64\n",
    "            )\n",
    "        self.rnn = nn.RNN(input_size=64,hidden_size=64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        _, out = self.rnn(out)\n",
    "        out = self.fc(out.squeeze(0))\n",
    "        return out\n",
    "\n",
    "vocab_size = len(vocab_dict)\n",
    "model = myrnnmodel(vocab_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 377])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_dataset[45][0]\n",
    "# print(x)\n",
    "embedding = nn.Embedding(\n",
    "                num_embeddings=vocab_size, \n",
    "                embedding_dim=64\n",
    "            )\n",
    "out = embedding(x)\n",
    "print(out.shape)\n",
    "rnn = nn.RNN(64,64)\n",
    "_, out = rnn(out)\n",
    "final = nn.Linear(64, vocab_size)\n",
    "out = final(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.008917331695557\n",
      "Epoch 11, Loss: 0.426745742559433\n",
      "Epoch 21, Loss: 0.05934172496199608\n",
      "Epoch 31, Loss: 0.007238590624183416\n",
      "Epoch 41, Loss: 0.011146065779030323\n",
      "Epoch 51, Loss: 0.0008330450509674847\n",
      "Epoch 61, Loss: 0.004755496513098478\n",
      "Epoch 71, Loss: 0.0031767638865858316\n",
      "Epoch 81, Loss: 0.0012318650260567665\n",
      "Epoch 91, Loss: 0.0004919749335385859\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        y_pred = model(batch_features)\n",
    "        loss = loss_fn(y_pred, batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the Geet's crush?\n",
      "Predicted Answer: aayushi\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is the Geet's crush?\"\n",
    "question_index = text_to_index(question, vocab_dict)\n",
    "question_index = torch.tensor(question_index).unsqueeze(0)\n",
    "question_index.shape\n",
    "y_pred = model(question_index)\n",
    "y_pred = y_pred.argmax(dim=1)\n",
    "answer = [k for k, v in vocab_dict.items() if v == y_pred.item()]\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Predicted Answer: {answer[0] if answer else 'No answer found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
