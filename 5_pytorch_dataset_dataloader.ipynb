{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset and Dataloader are the core abstraction of pytorch that define how you decouple how you define your data and how you efficeintly iterate over it in training loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset class  \n",
    "It's a blueprint that defines how data is loaded and returned.  \n",
    "\n",
    "- __init__() -> tells how data should be loaded  \n",
    "- __len__() -> returns total number os samples  \n",
    "- __getitem__(index) -> return data at the given index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader class\n",
    "It wraps a Dataset and handles batching, shuffling and parallelization  \n",
    "- it start of the epoch, shuffles indices(if needed)\n",
    "- for each index the data samples are fetched from Datset object using the __getitem__ fn  \n",
    "- The samples are collected and combined into a batch using collate_fn()  \n",
    "- the batch is returned into the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10, n_features=20, n_informative=10, n_redundant=5, random_state=42)\n",
    "\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =customDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.2870,  2.1296, -0.7116,  0.5766,  1.6450, -2.0425, -2.3476,  1.3669,\n",
       "          0.1319,  1.1865, -2.1554,  1.0296,  0.9065,  2.2981, -0.2490,  4.4895,\n",
       "         -4.4665,  2.2131, -1.5152,  3.9459]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7416,  0.2445, -4.4866,  0.6142, -0.1123, -0.7998, -0.3118,  0.2140,\n",
      "          0.7653,  3.0692, -1.0656, -3.0723,  0.8255, -3.4992, -0.2210, -3.9071,\n",
      "         -2.8510, -4.5253, -0.6997,  0.0410],\n",
      "        [-1.2693,  3.7263, -0.1237,  0.0353, -1.1979,  0.8271,  3.1815, -0.5536,\n",
      "          1.9978,  1.2473,  4.0500, -1.3506, -1.5733, -2.7079,  1.9647,  4.6150,\n",
      "         -1.1077, -0.0878, -1.0352, -0.0098]])\n",
      "tensor([1., 1.])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.4762,  1.4008, -4.4011, -0.6466, -0.7564, -2.6964,  0.9252,  0.2035,\n",
      "         -1.4872, -3.0416,  1.3323,  3.0823,  0.9999,  3.1608, -1.4223,  3.3862,\n",
      "         -2.2152,  0.0906, -1.6064, -0.2761],\n",
      "        [-3.5718, -0.0941,  0.1049,  1.4799,  0.8816,  0.0315, -3.0798,  1.6871,\n",
      "         -0.6928, -1.6571,  2.6018,  1.2493,  1.6031, -3.5134, -0.0080, -1.6477,\n",
      "         -3.7222,  0.8220, -1.0815, -3.5989]])\n",
      "tensor([1., 1.])\n",
      "--------------------------------------------------\n",
      "tensor([[-1.5700,  1.1844,  2.5197, -0.9555,  1.1196,  3.3819, -2.9944,  3.0789,\n",
      "          1.7876,  6.6020, -1.1574, -4.0400,  1.3849, -7.1879, -0.1279, -2.1254,\n",
      "         -4.7822, -1.1862,  0.3113,  2.1730],\n",
      "        [ 2.2870,  2.1296, -0.7116,  0.5766,  1.6450, -2.0425, -2.3476,  1.3669,\n",
      "          0.1319,  1.1865, -2.1554,  1.0296,  0.9065,  2.2981, -0.2490,  4.4895,\n",
      "         -4.4665,  2.2131, -1.5152,  3.9459]])\n",
      "tensor([0., 0.])\n",
      "--------------------------------------------------\n",
      "tensor([[-3.9367e-01, -1.2074e-01,  2.8888e+00, -2.3019e+00, -5.7582e-01,\n",
      "          2.2736e+00,  1.2879e+00, -5.3050e-01,  4.7691e-01, -1.9075e-01,\n",
      "          1.9153e-01,  6.2464e-02, -2.2875e+00, -3.4325e+00, -2.7505e-01,\n",
      "          1.2481e-02, -1.1138e+00,  7.3985e-01,  7.5751e-01,  2.4561e+00],\n",
      "        [ 1.0014e+00, -1.6453e+00,  1.5127e+00,  9.5514e-01, -1.0592e+00,\n",
      "          8.8160e-05,  1.4085e+00, -5.1387e-01, -9.0352e-01, -2.3425e-01,\n",
      "         -8.2512e-02,  2.1624e+00,  3.1721e+00,  8.2147e+00, -6.2679e-02,\n",
      "         -5.1563e-01,  4.7870e+00,  4.9651e+00, -9.3988e-01, -1.6101e+00]])\n",
      "tensor([1., 0.])\n",
      "--------------------------------------------------\n",
      "tensor([[-2.3077, -0.0726,  0.5184, -0.1070, -0.5303,  2.1855,  0.9607,  0.5040,\n",
      "         -2.4567, -0.5668,  0.8460,  0.5564,  2.0338,  3.7118, -0.7929, -1.8071,\n",
      "          2.6072,  3.3561, -0.9857, -2.2975],\n",
      "        [-1.2125, -1.4271,  3.3780,  0.3666, -1.3045,  1.5280, -2.0286, -0.0891,\n",
      "         -0.7416,  0.1833,  1.1937, -2.1845, -1.8303, -5.2701,  0.6697, -2.2507,\n",
      "          0.6752, -1.3678, -2.0674, -1.3019]])\n",
      "tensor([0., 0.])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for batch_features, batch_labels in dataloader:\n",
    "    print(batch_features)\n",
    "    print(batch_labels)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collate Function  \n",
    "The data loader uses a simple batch collation mechanism but collate functions allows us to customize how data should be processed and batched.  \n",
    "e.g Let's say we have a text dataset converted into tokens. Now the challenge is that we the sentences are of different lengths. In this case we modify the collate function to add padding to the batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number Of Workers  \n",
    "DataLoader allows multiprocessing by specifying num_workers as a parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing datasset and dataloader on cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df = df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataframe into train and test sets\n",
    "X = df.drop(\"diagnosis\", axis=1)\n",
    "y = df[\"diagnosis\"]\n",
    "\n",
    "ss= StandardScaler()\n",
    "X = ss.fit_transform(X.values)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train.values).float()\n",
    "x_test_tensor = torch.from_numpy(x_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = customDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = customDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self,x):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(x, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.network(x)\n",
    "        return out\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 0.582358717918396\n",
      "Loss after epoch 2: 0.46402010321617126\n",
      "Loss after epoch 3: 0.650102972984314\n",
      "Loss after epoch 4: 0.33554166555404663\n",
      "Loss after epoch 5: 0.33701494336128235\n",
      "Loss after epoch 6: 0.2150178849697113\n",
      "Loss after epoch 7: 0.3694963753223419\n",
      "Loss after epoch 8: 0.23097142577171326\n",
      "Loss after epoch 9: 0.22115285694599152\n",
      "Loss after epoch 10: 0.24354352056980133\n",
      "Loss after epoch 11: 0.21515612304210663\n",
      "Loss after epoch 12: 0.16019245982170105\n",
      "Loss after epoch 13: 0.23656785488128662\n",
      "Loss after epoch 14: 0.11940811574459076\n",
      "Loss after epoch 15: 0.04832916334271431\n",
      "Loss after epoch 16: 0.4020020365715027\n",
      "Loss after epoch 17: 0.09544921666383743\n",
      "Loss after epoch 18: 0.08118089288473129\n",
      "Loss after epoch 19: 0.2238500416278839\n",
      "Loss after epoch 20: 0.06868790090084076\n",
      "Loss after epoch 21: 0.05220610648393631\n",
      "Loss after epoch 22: 0.0772932916879654\n",
      "Loss after epoch 23: 0.12692147493362427\n",
      "Loss after epoch 24: 0.01513208169490099\n",
      "Loss after epoch 25: 0.03364253416657448\n"
     ]
    }
   ],
   "source": [
    "model = myModel(x_train_tensor.shape[1])\n",
    "\n",
    "epochs = 25\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        #forward_pass\n",
    "        y_pred = model(batch_features)\n",
    "\n",
    "        #loss_calculation\n",
    "        loss = loss_fn(y_pred, batch_labels.reshape(-1, 1))\n",
    "\n",
    "        #zero_grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #backward_pass\n",
    "        loss.backward()\n",
    "\n",
    "        #parameter_update_using_optimizer\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "    \n",
    "\n",
    "    print(f\"Loss after epoch {epoch+1}: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[71  0]\n",
      " [ 1 42]]\n",
      "Accuracy: 0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_test = model(x_test_tensor)\n",
    "    y_pred_test = (y_pred_test > 0.5).float()\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_tensor, y_pred_test)\n",
    "accuracy = accuracy_score(y_test_tensor, y_pred_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
