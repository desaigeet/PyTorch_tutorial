{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolution Neural Network  \n",
    "Convolution Neural Networks are a type of Deep Learning model that are specifiucally designed for Images and Videos.  \n",
    "Uses:  Image Classification, Object Detection etc  \n",
    "It has ability to learn spatial hieraarchies of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation to convert images to PyTorch tensors\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load the Fashion MNIST training dataset\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='./data',  # Directory to store the dataset\n",
    "    train=True,     # Specify this is the training set\n",
    "    download=True,  # Download the dataset if not already present\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Load the Fashion MNIST test dataset\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='./data',  # Directory to store the dataset\n",
    "    train=False,    # Specify this is the test set\n",
    "    download=True,  # Download the dataset if not already present\n",
    "    transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=256, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_data, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_cnn_model(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): LazyLinear(in_features=0, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class my_cnn_model(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_features, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "num_features = train_data[0][0].shape[0]\n",
    "model = my_cnn_model(num_features)\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 0.2140083909034729\n",
      "Loss after epoch 3: 0.2608056366443634\n",
      "Loss after epoch 5: 0.1749967783689499\n",
      "Loss after epoch 7: 0.12747584283351898\n",
      "Loss after epoch 9: 0.21175575256347656\n",
      "Loss after epoch 11: 0.15755312144756317\n",
      "Loss after epoch 13: 0.1633957028388977\n",
      "Loss after epoch 15: 0.018246613442897797\n",
      "Loss after epoch 17: 0.06495492905378342\n",
      "Loss after epoch 19: 0.07409251481294632\n",
      "Loss after epoch 21: 0.0693206787109375\n",
      "Loss after epoch 23: 0.057302992790937424\n",
      "Loss after epoch 25: 0.010069935582578182\n",
      "Loss after epoch 27: 0.010885455645620823\n",
      "Loss after epoch 29: 0.10230210423469543\n",
      "Loss after epoch 31: 0.08756810426712036\n",
      "Loss after epoch 33: 0.002805870957672596\n",
      "Loss after epoch 35: 0.012920464389026165\n",
      "Loss after epoch 37: 0.04106512665748596\n",
      "Loss after epoch 39: 0.0031726250890642405\n",
      "Loss after epoch 41: 0.009272154420614243\n",
      "Loss after epoch 43: 0.0027967102359980345\n",
      "Loss after epoch 45: 0.13214771449565887\n",
      "Loss after epoch 47: 0.0989958643913269\n",
      "Loss after epoch 49: 0.00787455216050148\n",
      "Loss after epoch 51: 0.10686719417572021\n",
      "Loss after epoch 53: 0.04125845432281494\n",
      "Loss after epoch 55: 0.007393214851617813\n",
      "Loss after epoch 57: 0.019485948607325554\n",
      "Loss after epoch 59: 0.027202246710658073\n",
      "Loss after epoch 61: 0.0007311804802156985\n",
      "Loss after epoch 63: 0.07748016715049744\n",
      "Loss after epoch 65: 0.008151964284479618\n",
      "Loss after epoch 67: 0.004743496421724558\n",
      "Loss after epoch 69: 0.023936064913868904\n",
      "Loss after epoch 71: 0.0033645182847976685\n",
      "Loss after epoch 73: 0.0011788065312430263\n",
      "Loss after epoch 75: 0.016682060435414314\n",
      "Loss after epoch 77: 0.0008080474217422307\n",
      "Loss after epoch 79: 0.037688348442316055\n",
      "Loss after epoch 81: 0.017788836732506752\n",
      "Loss after epoch 83: 0.001544379978440702\n",
      "Loss after epoch 85: 0.013265389949083328\n",
      "Loss after epoch 87: 0.10631566494703293\n",
      "Loss after epoch 89: 0.038864996284246445\n",
      "Loss after epoch 91: 0.00010854154243133962\n",
      "Loss after epoch 93: 0.00526469899341464\n",
      "Loss after epoch 95: 0.01979074254631996\n",
      "Loss after epoch 97: 0.008810833096504211\n",
      "Loss after epoch 99: 0.011373725719749928\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        y_pred = model(batch_features)\n",
    "        loss = loss_fn(y_pred, batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%2 == 0:\n",
    "        print(f\"Loss after epoch {epoch + 1}: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Accuracy: 0.9159\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy_list = []\n",
    "for batch_features, batch_labels in test_dataloader:\n",
    "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "    y_pred = model(batch_features)\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    accuracy = accuracy_score(batch_labels.cpu(), predicted.cpu())\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f\"Average Test Accuracy: {average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Accuracy: 0.9969\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for batch_features, batch_labels in train_dataloader:\n",
    "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "    y_pred = model(batch_features)\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    accuracy = accuracy_score(batch_labels.cpu(), predicted.cpu())\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "average_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f\"Average Test Accuracy: {average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
